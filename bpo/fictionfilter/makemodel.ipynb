{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing a fiction filter\n",
    "\n",
    "This very simply loads some training data and trains a regularized logistic regression on it, using gridsearch to find an optimal number of features and regularization constant. We optimize on F0.5 score, a harmonic mean of precision and recall that puts more emphasis on precision. In practice, I don't think this produces results hugely different from F1 score.\n",
    "\n",
    "There are more sophisticated feature-selection strategies than simply using *n* most common, but if I used more sophisticated selection strategies I would also need a more sophisticated validation strategy to avoid fooling myself; e.g. a validation set separate from the test set. Without extensive resources for generating labeled data, I'm trying to keep things relatively quick and simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tunder/miniconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequenceID</th>\n",
       "      <th>genrecode</th>\n",
       "      <th>#matchquality</th>\n",
       "      <th>#rareword</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>and</th>\n",
       "      <th>a</th>\n",
       "      <th>is</th>\n",
       "      <th>to</th>\n",
       "      <th>...</th>\n",
       "      <th>title</th>\n",
       "      <th>air</th>\n",
       "      <th>four</th>\n",
       "      <th>neither</th>\n",
       "      <th>latter</th>\n",
       "      <th>beauty</th>\n",
       "      <th>lord</th>\n",
       "      <th>y</th>\n",
       "      <th>u</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>573</td>\n",
       "      <td>y</td>\n",
       "      <td>2.502942</td>\n",
       "      <td>0.311475</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.042623</td>\n",
       "      <td>0.026230</td>\n",
       "      <td>0.039344</td>\n",
       "      <td>0.026230</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>208-2</td>\n",
       "      <td>y</td>\n",
       "      <td>3.153019</td>\n",
       "      <td>0.281944</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.080556</td>\n",
       "      <td>0.030556</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>315-3</td>\n",
       "      <td>y</td>\n",
       "      <td>2.356600</td>\n",
       "      <td>0.376190</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202</td>\n",
       "      <td>y</td>\n",
       "      <td>2.834483</td>\n",
       "      <td>0.325893</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.075893</td>\n",
       "      <td>0.040179</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.013393</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>460</td>\n",
       "      <td>y</td>\n",
       "      <td>2.256718</td>\n",
       "      <td>0.307233</td>\n",
       "      <td>0.036461</td>\n",
       "      <td>0.050209</td>\n",
       "      <td>0.028691</td>\n",
       "      <td>0.025702</td>\n",
       "      <td>0.019127</td>\n",
       "      <td>0.022116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sequenceID genrecode  #matchquality  #rareword        of       the  \\\n",
       "0        573         y       2.502942   0.311475  0.049180  0.042623   \n",
       "1      208-2         y       3.153019   0.281944  0.037500  0.080556   \n",
       "2      315-3         y       2.356600   0.376190  0.047619  0.061905   \n",
       "3        202         y       2.834483   0.325893  0.062500  0.075893   \n",
       "4        460         y       2.256718   0.307233  0.036461  0.050209   \n",
       "\n",
       "        and         a        is        to   ...    title       air      four  \\\n",
       "0  0.026230  0.039344  0.026230  0.016393   ...      0.0  0.000000  0.000000   \n",
       "1  0.030556  0.033333  0.025000  0.027778   ...      0.0  0.000000  0.001389   \n",
       "2  0.028571  0.023810  0.014286  0.009524   ...      0.0  0.000000  0.000000   \n",
       "3  0.040179  0.031250  0.013393  0.017857   ...      0.0  0.000000  0.000000   \n",
       "4  0.028691  0.025702  0.019127  0.022116   ...      0.0  0.000598  0.000000   \n",
       "\n",
       "   neither    latter    beauty  lord    y         u  number  \n",
       "0      0.0  0.000000  0.000000   0.0  0.0  0.000000     0.0  \n",
       "1      0.0  0.000000  0.000000   0.0  0.0  0.000000     0.0  \n",
       "2      0.0  0.000000  0.000000   0.0  0.0  0.000000     0.0  \n",
       "3      0.0  0.000000  0.000000   0.0  0.0  0.000000     0.0  \n",
       "4      0.0  0.000598  0.000598   0.0  0.0  0.000598     0.0  \n",
       "\n",
       "[5 rows x 402 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata = pd.read_csv('trainingdata.tsv', sep = '\\t')\n",
    "rawdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the complete dataset as it exists on disk. We may not use all the features. Notice how the most common feature is '#rareword', i.e., English word outside this limited vocabulary.\n",
    "\n",
    "We're going to select only the columns for features, leaving out the first two metadata columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478, 400)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "termdoc = rawdata.iloc[ : , 2 : 402]\n",
    "termdoc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a vector that maps genrecode (is it fiction n/y) to an integer code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classvec = rawdata.genrecode.map({'n' : 0, 'y': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the function that actually trains a logistic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onepass(cval, numfeatures, termdoc, classvec):\n",
    "    '''\n",
    "    cval is the regularization constant\n",
    "    numfeatures the number of features to use in the model\n",
    "    termdoc is X, aka the feature matrix\n",
    "    classvec is y, aka the vector of class integers to be predicted\n",
    "    '''\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(termdoc.iloc[ : , 0 : numfeatures])\n",
    "    \n",
    "    # Note that we scale and center the columns of the feature matrix.\n",
    "    \n",
    "    model = LogisticRegression(C = cval)\n",
    "    f1_scores = cross_val_score(model, data, classvec,\n",
    "                             scoring = 'f1', cv=10)\n",
    "    f1 = sum(f1_scores) / len(f1_scores)\n",
    "    # Tenfold crossvalidation, using F1 score.\n",
    "    \n",
    "    precision_scores = cross_val_score(model, data, classvec,\n",
    "                             scoring = 'precision', cv=10)\n",
    "    precision = sum(precision_scores) / len(precision_scores)\n",
    "    \n",
    "    recall_scores = cross_val_score(model, data, classvec,\n",
    "                             scoring = 'recall', cv=10)\n",
    "    recall = sum(recall_scores) / len(recall_scores)\n",
    "    \n",
    "    f05 = 1.5 * (precision * recall) / ((.5 * precision) + recall)\n",
    "    \n",
    "    model.fit(data, classvec)\n",
    "    predictions = model.predict(data)\n",
    "    \n",
    "    # We return both the average F1 score of a cross-\n",
    "    # validated model, and the predictions of a model\n",
    "    # trained on all the data.\n",
    "    \n",
    "    return f05, precision, recall, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search across a range of feature numbers and regularization constants. Notice that for regularization, we iterate across an integer range but then divide by ten thousand. So the best value of 100 is actually .01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.879913433764 250 90\n",
      "0.879913433764 260 90\n",
      "0.879913433764 270 90\n",
      "0.882781368353 280 90\n",
      "0.882781368353 290 90\n",
      "0.883959573752 300 90\n",
      "0.88193014606 310 90\n",
      "0.885497356017 320 90\n",
      "0.887303470197 330 90\n",
      "0.885725046533 340 90\n",
      "0.885725046533 350 90\n",
      "0.885725046533 360 90\n",
      "0.887022044355 370 90\n",
      "0.887022044355 380 90\n",
      "0.887022044355 390 90\n",
      "0.883897694666 400 90\n",
      "0.883897694666 410 90\n",
      "0.883897694666 420 90\n",
      "0.882266052414 430 90\n",
      "0.882266052414 440 90\n",
      "0.883412854045 450 90\n",
      "0.883412854045 460 90\n",
      "0.885064673086 470 90\n",
      "0.885064673086 480 90\n",
      "0.885064673086 490 90\n",
      "0.88479005475 250 95\n",
      "0.886584724374 260 95\n",
      "0.886584724374 270 95\n",
      "0.886584724374 280 95\n",
      "0.886584724374 290 95\n",
      "0.886584724374 300 95\n",
      "0.883222033492 310 95\n",
      "0.883222033492 320 95\n",
      "0.883222033492 330 95\n",
      "0.884444179709 340 95\n",
      "0.884444179709 350 95\n",
      "0.883200451949 360 95\n",
      "0.883200451949 370 95\n",
      "0.887531920866 380 95\n",
      "0.887531920866 390 95\n",
      "0.887531920866 400 95\n",
      "0.888752515861 410 95\n",
      "0.888752515861 420 95\n",
      "0.888752515861 430 95\n",
      "0.888752515861 440 95\n",
      "0.888752515861 450 95\n",
      "0.888035363401 460 95\n",
      "0.885630556914 470 95\n",
      "0.885630556914 480 95\n",
      "0.885630556914 490 95\n",
      "0.887180651444 250 100\n",
      "0.889130608618 260 100\n",
      "0.889130608618 270 100\n",
      "0.889130608618 280 100\n",
      "0.890905342041 290 100\n",
      "0.892578960665 300 100\n",
      "0.892578960665 310 100\n",
      "0.892578960665 320 100\n",
      "0.89259099237 330 100\n",
      "0.89259099237 340 100\n",
      "0.891055573225 350 100\n",
      "0.891055573225 360 100\n",
      "0.891055573225 370 100\n",
      "0.891055573225 380 100\n",
      "0.891055573225 390 100\n",
      "0.891055573225 400 100\n",
      "0.88742305646 410 100\n",
      "0.88742305646 420 100\n",
      "0.88742305646 430 100\n",
      "0.88742305646 440 100\n",
      "0.88742305646 450 100\n",
      "0.88742305646 460 100\n",
      "0.88742305646 470 100\n",
      "0.88742305646 480 100\n",
      "0.88742305646 490 100\n",
      "0.892999252429 250 105\n",
      "0.894268681382 260 105\n",
      "0.895574760884 270 105\n",
      "0.893523702423 280 105\n",
      "0.893523702423 290 105\n",
      "0.897374376049 300 105\n",
      "0.898988140795 310 105\n",
      "0.898988140795 320 105\n",
      "0.898988140795 330 105\n",
      "0.898988140795 340 105\n",
      "0.898988140795 350 105\n",
      "0.898988140795 360 105\n",
      "0.898988140795 370 105\n",
      "0.900156246566 380 105\n",
      "0.899336310517 390 105\n",
      "0.899336310517 400 105\n",
      "0.899336310517 410 105\n",
      "0.899336310517 420 105\n",
      "0.899336310517 430 105\n",
      "0.899336310517 440 105\n",
      "0.897451975945 450 105\n",
      "0.897247099597 460 105\n",
      "0.897247099597 470 105\n",
      "0.897247099597 480 105\n",
      "0.897247099597 490 105\n",
      "0.899667076296 250 110\n",
      "0.899667076296 260 110\n",
      "0.899667076296 270 110\n",
      "0.900917812185 280 110\n",
      "0.900917812185 290 110\n",
      "0.900917812185 300 110\n",
      "0.903280346274 310 110\n",
      "0.903280346274 320 110\n",
      "0.903280346274 330 110\n",
      "0.903280346274 340 110\n",
      "0.903280346274 350 110\n",
      "0.904906282689 360 110\n",
      "0.904906282689 370 110\n",
      "0.906168060254 380 110\n",
      "0.906168060254 390 110\n",
      "0.906168060254 400 110\n",
      "0.904166843845 410 110\n",
      "0.904166843845 420 110\n",
      "0.904166843845 430 110\n",
      "0.904166843845 440 110\n",
      "0.901277680785 450 110\n",
      "0.899397628014 460 110\n",
      "0.899397628014 470 110\n",
      "0.897333657624 480 110\n",
      "0.896156965618 490 110\n",
      "0.900655281875 250 115\n",
      "0.900655281875 260 115\n",
      "0.900987772279 270 115\n",
      "0.90223072338 280 115\n",
      "0.90223072338 290 115\n",
      "0.90223072338 300 115\n",
      "0.90214502927 310 115\n",
      "0.90214502927 320 115\n",
      "0.90214502927 330 115\n",
      "0.903320407499 340 115\n",
      "0.903320407499 350 115\n",
      "0.903320407499 360 115\n",
      "0.903320407499 370 115\n",
      "0.903320407499 380 115\n",
      "0.904659223001 390 115\n",
      "0.904659223001 400 115\n",
      "0.904659223001 410 115\n",
      "0.904659223001 420 115\n",
      "0.903424301191 430 115\n",
      "0.903424301191 440 115\n",
      "0.901431215574 450 115\n",
      "0.901431215574 460 115\n",
      "0.897811097992 470 115\n",
      "0.897811097992 480 115\n",
      "0.897811097992 490 115\n"
     ]
    }
   ],
   "source": [
    "bestscores = []\n",
    "for features in range(90, 120, 5):\n",
    "    for cval in range(250, 500, 10):\n",
    "        f05, precision, recall, predictions = onepass(cval/ 10000, features, termdoc, classvec)\n",
    "        print(f05, cval, features)\n",
    "        bestscores.append((f05, cval, features))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.90616806025370267, 400, 110)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestscores.sort()\n",
    "bestscores[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the best model more specifically. Note that precision is good, which is important.\n",
    "\n",
    "**Recall 78.8, precision 94.4.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.906168060254 0.924118143347 0.872281639929 332\n"
     ]
    }
   ],
   "source": [
    "f05, precision, recall, predictions = onepass(.04, 110, termdoc, classvec)\n",
    "print(f05, precision, recall, sum(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Produce a model to export\n",
    "\n",
    "Ultimately we have to make a model to use, and this can't be crossvalidated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained.\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(termdoc.iloc[ : , 0 : 110])\n",
    "model = LogisticRegression(C = .04)\n",
    "model.fit(data, classvec)\n",
    "print('Model trained.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model/fictionreview_scaler.pkl', mode = 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "with open('model/fictionreview_model.pkl', mode = 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "words = list(termdoc.columns)\n",
    "with open('model/fictionreview_vocab.txt', mode = 'w', encoding = 'utf-8') as f:\n",
    "    for w in words[0: 400]:\n",
    "        f.write(w + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we actually export it.\n",
    "\n",
    "#### Examine feature weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(termdoc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#placename -0.33072670946\n",
      "voyages -0.318318190897\n",
      "letters -0.316025820311\n",
      "which -0.291357045877\n",
      "on -0.243732293916\n",
      "was -0.230331603847\n",
      "of -0.175099206423\n",
      "book -0.142205727355\n",
      "#rareword -0.141257546259\n",
      "own -0.134639885455\n",
      "as -0.133043067259\n",
      "it -0.127656254876\n",
      "when -0.12318173239\n",
      "we -0.115418103708\n",
      "no -0.109214407898\n",
      "from -0.10667403415\n",
      "would -0.10652392581\n",
      "can -0.105381511701\n",
      "#notenglishword -0.0998335574906\n",
      "been -0.0939636197274\n",
      "even -0.0938568671482\n",
      "those -0.0876184890147\n",
      "be -0.0874594975767\n",
      "this -0.0744574674843\n",
      "time -0.0719073164952\n",
      "most -0.0697927930797\n",
      "well -0.0686736966787\n",
      "have -0.0678855792873\n",
      "i -0.0672386863886\n",
      "after -0.0662116972901\n",
      "#romannumeral -0.0617962840391\n",
      "and -0.0611271990167\n",
      "mr -0.0576872796678\n",
      "such -0.0567907944629\n",
      "first -0.0566274716723\n",
      "he -0.0521599916035\n",
      "they -0.0517693306687\n",
      "these -0.0505014664264\n",
      "to -0.0415642129724\n",
      "or -0.0385367708727\n",
      "than -0.0379260092442\n",
      "work -0.036809250317\n",
      "that -0.0312364837234\n",
      "if -0.0304267378171\n",
      "may -0.0287708380732\n",
      "us -0.020659046931\n",
      "its -0.0172658424132\n",
      "many -0.0139759722809\n",
      "other -0.0133246522261\n",
      "about -0.0119889666522\n",
      "one -0.00843617926906\n",
      "who -0.00585920851506\n",
      "were -0.00362504492319\n",
      "great -0.00356537179638\n",
      "any -0.000984739092365\n",
      "with 0.00259991971377\n",
      "what 0.00559837026936\n",
      "him 0.00600338164271\n",
      "their 0.00776921766407\n",
      "upon 0.013979801875\n",
      "so 0.0151399952957\n",
      "#personalname 0.0156221634001\n",
      "there 0.0172189986642\n",
      "some 0.0180334801207\n",
      "not 0.0183005964652\n",
      "all 0.0199121519152\n",
      "in 0.0215665979908\n",
      "up 0.0219902877328\n",
      "an 0.0239967174196\n",
      "into 0.0255894406452\n",
      "had 0.0263553053946\n",
      "out 0.0283654715991\n",
      "should 0.0298613963944\n",
      "will 0.0329880736759\n",
      "man 0.0358013574485\n",
      "life 0.0373790658314\n",
      "are 0.0396469922256\n",
      "only 0.0444014962396\n",
      "s 0.0454402975528\n",
      "them 0.0461681818205\n",
      "at 0.0535206761404\n",
      "old 0.0677162313326\n",
      "by 0.0705047250072\n",
      "though 0.0745687587797\n",
      "his 0.0776222577623\n",
      "author 0.0785333153337\n",
      "much 0.081581750901\n",
      "two 0.102791288337\n",
      "has 0.107701461638\n",
      "little 0.108397952071\n",
      "good 0.119397790859\n",
      "like 0.122202682955\n",
      "she 0.124622541154\n",
      "for 0.135739966055\n",
      "but 0.136209364304\n",
      "her 0.142654113247\n",
      "the 0.145467392963\n",
      "very 0.146413036386\n",
      "our 0.149273770629\n",
      "a 0.149396125614\n",
      "tales 0.1664258648\n",
      "more 0.170122698761\n",
      "characters 0.216929882878\n",
      "too 0.240389493416\n",
      "tale 0.305999052184\n",
      "is 0.306945029537\n",
      "novels 0.315157287354\n",
      "#matchquality 0.351752235489\n",
      "novel 0.383559045773\n",
      "story 0.424344104807\n"
     ]
    }
   ],
   "source": [
    "features = list(zip(list(model.coef_[0]), words[0: 110]))\n",
    "features.sort()\n",
    "for x, y in features:\n",
    "    print(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
