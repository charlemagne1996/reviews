{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing a fiction filter\n",
    "\n",
    "This very simply loads some training data and trains a regularized logistic regression on it, using gridsearch to find an optimal number of features and regularization constant. We optimize on F1 score.\n",
    "\n",
    "There are more sophisticated feature-selection strategies than this, but if I used them I would also need a more sophisticated validation strategy to avoid fooling myself; e.g. a validation set separate from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequenceID</th>\n",
       "      <th>genrecode</th>\n",
       "      <th>#matchquality</th>\n",
       "      <th>#rareword</th>\n",
       "      <th>the</th>\n",
       "      <th>of</th>\n",
       "      <th>and</th>\n",
       "      <th>a</th>\n",
       "      <th>is</th>\n",
       "      <th>to</th>\n",
       "      <th>...</th>\n",
       "      <th>air</th>\n",
       "      <th>title</th>\n",
       "      <th>neither</th>\n",
       "      <th>four</th>\n",
       "      <th>hope</th>\n",
       "      <th>especially</th>\n",
       "      <th>able</th>\n",
       "      <th>y</th>\n",
       "      <th>used</th>\n",
       "      <th>somewhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159-3</td>\n",
       "      <td>y</td>\n",
       "      <td>2.640870</td>\n",
       "      <td>0.494662</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>208-1</td>\n",
       "      <td>y</td>\n",
       "      <td>3.153019</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>533</td>\n",
       "      <td>y</td>\n",
       "      <td>2.260767</td>\n",
       "      <td>0.778061</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>352</td>\n",
       "      <td>y</td>\n",
       "      <td>2.654242</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>433</td>\n",
       "      <td>y</td>\n",
       "      <td>3.043333</td>\n",
       "      <td>0.564748</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sequenceID genrecode  #matchquality  #rareword       the        of  \\\n",
       "0      159-3         y       2.640870   0.494662  0.003559  0.003559   \n",
       "1      208-1         y       3.153019   0.535714  0.004464  0.004464   \n",
       "2        533         y       2.260767   0.778061  0.001276  0.001276   \n",
       "3        352         y       2.654242   0.459016  0.008197  0.008197   \n",
       "4        433         y       3.043333   0.564748  0.003597  0.003597   \n",
       "\n",
       "        and         a        is        to    ...          air  title  neither  \\\n",
       "0  0.003559  0.003559  0.003559  0.003559    ...     0.000000    0.0      0.0   \n",
       "1  0.004464  0.004464  0.004464  0.004464    ...     0.000000    0.0      0.0   \n",
       "2  0.001276  0.001276  0.001276  0.001276    ...     0.001276    0.0      0.0   \n",
       "3  0.008197  0.008197  0.008197  0.008197    ...     0.000000    0.0      0.0   \n",
       "4  0.003597  0.003597  0.003597  0.003597    ...     0.000000    0.0      0.0   \n",
       "\n",
       "   four      hope  especially  able         y  used  somewhat  \n",
       "0   0.0  0.000000    0.000000   0.0  0.000000   0.0  0.000000  \n",
       "1   0.0  0.000000    0.000000   0.0  0.000000   0.0  0.000000  \n",
       "2   0.0  0.001276    0.001276   0.0  0.001276   0.0  0.000000  \n",
       "3   0.0  0.000000    0.000000   0.0  0.000000   0.0  0.000000  \n",
       "4   0.0  0.000000    0.000000   0.0  0.000000   0.0  0.003597  \n",
       "\n",
       "[5 rows x 402 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata = pd.read_csv('trainingdata.tsv', sep = '\\t')\n",
    "rawdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the complete dataset as it exists on disk. We may not use all the features. Notice how the most common feature is '#rareword', i.e., English word outside this limited vocabulary.\n",
    "\n",
    "We're going to select only the columns for features, leaving out the first two metadata columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(505, 400)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "termdoc = rawdata.iloc[ : , 2 : 402]\n",
    "termdoc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a vector that maps genrecode (is it fiction n/y) to an integer code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classvec = rawdata.genrecode.map({'n' : 0, 'y': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the function that actually trains a logistic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onepass(cval, numfeatures, termdoc, classvec):\n",
    "    '''\n",
    "    cval is the regularization constant\n",
    "    numfeatures the number of features to use in the model\n",
    "    termdoc is X, aka the feature matrix\n",
    "    classvec is y, aka the vector of class integers to be predicted\n",
    "    '''\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(termdoc.iloc[ : , 0 : numfeatures])\n",
    "    \n",
    "    # Note that we scale and center the columns of the feature matrix.\n",
    "    \n",
    "    model = LogisticRegression(C = cval)\n",
    "    f1_scores = cross_val_score(model, data, classvec,\n",
    "                             scoring = 'f1', cv=10)\n",
    "    f1 = sum(f1_scores) / len(f1_scores)\n",
    "    # Tenfold crossvalidation, using F1 score.\n",
    "    \n",
    "    precision_scores = cross_val_score(model, data, classvec,\n",
    "                             scoring = 'precision', cv=10)\n",
    "    precision = sum(precision_scores) / len(precision_scores)\n",
    "    \n",
    "    recall_scores = cross_val_score(model, data, classvec,\n",
    "                             scoring = 'recall', cv=10)\n",
    "    recall = sum(recall_scores) / len(recall_scores)\n",
    "    \n",
    "    f05 = 1.5 * (precision * recall) / ((.5 * precision) + recall)\n",
    "    \n",
    "    model.fit(data, classvec)\n",
    "    predictions = model.predict(data)\n",
    "    \n",
    "    # We return both the average F1 score of a cross-\n",
    "    # validated model, and the predictions of a model\n",
    "    # trained on all the data.\n",
    "    \n",
    "    return f05, precision, recall, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search across a range of feature numbers and regularization constants. Notice that for regularization, we iterate across an integer range but then divide by ten thousand. So the best value of 100 is actually .01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85683704973 50 120\n",
      "0.861683416155 60 120\n",
      "0.858961325994 70 120\n",
      "0.857602791495 80 120\n",
      "0.856370414361 90 120\n",
      "0.855232812036 100 120\n",
      "0.854915235916 110 120\n",
      "0.851610037983 120 120\n",
      "0.852932623746 130 120\n",
      "0.855852534695 140 120\n",
      "0.855370144368 150 120\n",
      "0.856631519174 160 120\n",
      "0.854998611147 170 120\n",
      "0.854998611147 180 120\n",
      "0.859094302128 190 120\n",
      "0.856821836083 200 120\n",
      "0.858045871754 210 120\n",
      "0.856732712898 220 120\n",
      "0.857921654117 230 120\n",
      "0.857921654117 240 120\n",
      "0.857921654117 250 120\n",
      "0.857921654117 260 120\n",
      "0.857921654117 270 120\n",
      "0.859166350946 280 120\n",
      "0.860393096469 290 120\n",
      "0.842814356705 50 130\n",
      "0.850442234559 60 130\n",
      "0.850652474582 70 130\n",
      "0.847433497516 80 130\n",
      "0.842653638268 90 130\n",
      "0.842723894971 100 130\n",
      "0.847116179664 110 130\n",
      "0.847116179664 120 130\n",
      "0.846698084797 130 130\n",
      "0.849531058092 140 130\n",
      "0.851833768059 150 130\n",
      "0.851833768059 160 130\n",
      "0.851790384493 170 130\n",
      "0.851790384493 180 130\n",
      "0.854484237221 190 130\n",
      "0.855809644841 200 130\n",
      "0.857546665287 210 130\n",
      "0.858540734701 220 130\n",
      "0.859791648499 230 130\n",
      "0.861043583404 240 130\n",
      "0.859244798825 250 130\n",
      "0.863165470094 260 130\n",
      "0.863165470094 270 130\n",
      "0.862827791789 280 130\n",
      "0.862827791789 290 130\n",
      "0.842884543156 50 140\n",
      "0.84492477541 60 140\n",
      "0.843991165561 70 140\n",
      "0.851181562688 80 140\n",
      "0.852724778142 90 140\n",
      "0.852682141837 100 140\n",
      "0.852595992806 110 140\n",
      "0.851140783257 120 140\n",
      "0.853732695034 130 140\n",
      "0.851765564041 140 140\n",
      "0.853144794257 150 140\n",
      "0.851713526726 160 140\n",
      "0.852969752484 170 140\n",
      "0.854360886737 180 140\n",
      "0.858459565616 190 140\n",
      "0.857856593202 200 140\n",
      "0.86044046242 210 140\n",
      "0.86008596408 220 140\n",
      "0.858403885527 230 140\n",
      "0.858403885527 240 140\n",
      "0.858403885527 250 140\n",
      "0.860148372299 260 140\n",
      "0.859638682549 270 140\n",
      "0.859638682549 280 140\n",
      "0.860919741956 290 140\n",
      "0.844653459153 50 150\n",
      "0.850972374153 60 150\n",
      "0.866136129405 70 150\n",
      "0.864681698376 80 150\n",
      "0.865857796283 90 150\n",
      "0.865604813954 100 150\n",
      "0.866075520057 110 150\n",
      "0.862403911188 120 150\n",
      "0.863735095232 130 150\n",
      "0.861904237647 140 150\n",
      "0.861904237647 150 150\n",
      "0.860565303915 160 150\n",
      "0.861893043568 170 150\n",
      "0.863241366343 180 150\n",
      "0.862805548873 190 150\n",
      "0.865440099017 200 150\n",
      "0.865440099017 210 150\n",
      "0.867782552648 220 150\n",
      "0.869414206263 230 150\n",
      "0.870706573374 240 150\n",
      "0.870706573374 250 150\n",
      "0.873193688379 260 150\n",
      "0.873193688379 270 150\n",
      "0.871909918473 280 150\n",
      "0.871079197104 290 150\n",
      "0.847081242346 50 160\n",
      "0.853751042084 60 160\n",
      "0.855602597857 70 160\n",
      "0.859754320473 80 160\n",
      "0.863880168573 90 160\n",
      "0.865127181041 100 160\n",
      "0.863343720348 110 160\n",
      "0.865837375751 120 160\n",
      "0.865408492313 130 160\n",
      "0.866682253679 140 160\n",
      "0.866682253679 150 160\n",
      "0.862296291738 160 160\n",
      "0.863728510561 170 160\n",
      "0.863728510561 180 160\n",
      "0.864032583438 190 160\n",
      "0.865512873043 200 160\n",
      "0.865089475188 210 160\n",
      "0.866494026517 220 160\n",
      "0.866494026517 230 160\n",
      "0.867876640155 240 160\n",
      "0.867380463571 250 160\n",
      "0.866199501785 260 160\n",
      "0.866662560663 270 160\n",
      "0.870385401239 280 160\n",
      "0.870385401239 290 160\n",
      "0.857074153719 50 170\n",
      "0.856386507729 60 170\n",
      "0.858083811397 70 170\n",
      "0.865032868153 80 170\n",
      "0.8692292144 90 170\n",
      "0.871857915486 100 170\n",
      "0.873257658627 110 170\n",
      "0.870748700577 120 170\n",
      "0.867679029143 130 170\n",
      "0.867201544204 140 170\n",
      "0.870442269764 150 170\n",
      "0.871155857245 160 170\n",
      "0.870967550553 170 170\n",
      "0.872343658223 180 170\n",
      "0.872343658223 190 170\n",
      "0.872343658223 200 170\n",
      "0.873535346869 210 170\n",
      "0.873535346869 220 170\n",
      "0.873535346869 230 170\n",
      "0.869977699913 240 170\n",
      "0.872596322166 250 170\n",
      "0.869576900307 260 170\n",
      "0.870679814549 270 170\n",
      "0.870679814549 280 170\n",
      "0.869185712912 290 170\n",
      "0.847302955572 50 180\n",
      "0.848560962287 60 180\n",
      "0.856440709425 70 180\n",
      "0.859614942784 80 180\n",
      "0.859614942784 90 180\n",
      "0.862189581105 100 180\n",
      "0.859215100348 110 180\n",
      "0.860423464724 120 180\n",
      "0.860423464724 130 180\n",
      "0.861346530903 140 180\n",
      "0.859882749929 150 180\n",
      "0.858024565257 160 180\n",
      "0.854884155674 170 180\n",
      "0.85357296467 180 180\n",
      "0.85357296467 190 180\n",
      "0.853148415149 200 180\n",
      "0.856272303141 210 180\n",
      "0.857591712667 220 180\n",
      "0.855946771651 230 180\n",
      "0.858768216153 240 180\n",
      "0.860194059912 250 180\n",
      "0.8613194782 260 180\n",
      "0.8613194782 270 180\n",
      "0.8613194782 280 180\n",
      "0.8613194782 290 180\n",
      "0.845362846937 50 190\n",
      "0.848195374113 60 190\n",
      "0.848689675212 70 190\n",
      "0.848689675212 80 190\n",
      "0.848385109051 90 190\n",
      "0.848385109051 100 190\n",
      "0.854380433905 110 190\n",
      "0.852585933469 120 190\n",
      "0.854299055603 130 190\n",
      "0.855256405678 140 190\n",
      "0.854673138879 150 190\n",
      "0.859941098864 160 190\n",
      "0.861550011868 170 190\n",
      "0.856642554245 180 190\n",
      "0.853538781385 190 190\n",
      "0.854931063053 200 190\n",
      "0.856283918951 210 190\n",
      "0.856283918951 220 190\n",
      "0.856283918951 230 190\n",
      "0.857740263534 240 190\n",
      "0.856131607625 250 190\n",
      "0.857262701694 260 190\n",
      "0.858177936663 270 190\n",
      "0.858177936663 280 190\n",
      "0.86071746262 290 190\n",
      "0.849683683118 50 200\n",
      "0.851938393603 60 200\n",
      "0.855923876941 70 200\n",
      "0.85457401299 80 200\n",
      "0.851101090639 90 200\n",
      "0.851145755372 100 200\n",
      "0.854000161037 110 200\n",
      "0.854090822493 120 200\n",
      "0.85371786578 130 200\n",
      "0.856745423644 140 200\n",
      "0.859350063882 150 200\n",
      "0.860254871333 160 200\n",
      "0.86286168362 170 200\n",
      "0.864157629221 180 200\n",
      "0.868316049476 190 200\n",
      "0.870714766695 200 200\n",
      "0.874365491642 210 200\n",
      "0.870899359438 220 200\n",
      "0.869668793162 230 200\n",
      "0.869668793162 240 200\n",
      "0.868338415517 250 200\n",
      "0.868338415517 260 200\n",
      "0.869734323909 270 200\n",
      "0.870976357271 280 200\n",
      "0.870976357271 290 200\n",
      "0.853447647532 50 210\n",
      "0.85616809389 60 210\n",
      "0.858839688131 70 210\n",
      "0.855007512223 80 210\n",
      "0.850266987996 90 210\n",
      "0.848412654042 100 210\n",
      "0.849806558618 110 210\n",
      "0.849806558618 120 210\n",
      "0.852506274746 130 210\n",
      "0.852506274746 140 210\n",
      "0.856763355671 150 210\n",
      "0.858089133804 160 210\n",
      "0.85673322892 170 210\n",
      "0.859371012808 180 210\n",
      "0.861854511863 190 210\n",
      "0.861854511863 200 210\n",
      "0.861854511863 210 210\n",
      "0.861854511863 220 210\n",
      "0.863224899566 230 210\n",
      "0.864138519559 240 210\n",
      "0.865512285432 250 210\n",
      "0.866774566146 260 210\n",
      "0.870708251773 270 210\n",
      "0.870708251773 280 210\n",
      "0.870708251773 290 210\n",
      "0.849528148259 50 220\n",
      "0.851897222749 60 220\n",
      "0.85032423154 70 220\n",
      "0.851820390149 80 220\n",
      "0.854606028303 90 220\n",
      "0.853965183075 100 220\n",
      "0.854893752103 110 220\n",
      "0.854660693391 120 220\n",
      "0.855890147704 130 220\n",
      "0.857200121103 140 220\n",
      "0.858526795179 150 220\n",
      "0.858526795179 160 220\n",
      "0.86382170145 170 220\n",
      "0.864095248574 180 220\n",
      "0.862687908692 190 220\n",
      "0.862687908692 200 220\n",
      "0.863983520776 210 220\n",
      "0.862542698541 220 220\n",
      "0.863820430648 230 220\n",
      "0.862144746312 240 220\n",
      "0.86341950477 250 220\n",
      "0.86341950477 260 220\n",
      "0.864813486781 270 220\n",
      "0.864813486781 280 220\n",
      "0.864813486781 290 220\n",
      "0.854725315321 50 230\n",
      "0.860636748502 60 230\n",
      "0.857239845171 70 230\n",
      "0.861673148835 80 230\n",
      "0.864376609842 90 230\n",
      "0.867644030382 100 230\n",
      "0.868986562008 110 230\n",
      "0.87039695309 120 230\n",
      "0.870242941942 130 230\n",
      "0.872499022621 140 230\n",
      "0.868850648699 150 230\n",
      "0.868762437107 160 230\n",
      "0.86989558049 170 230\n",
      "0.86989558049 180 230\n",
      "0.876638223648 190 230\n",
      "0.875299075117 200 230\n",
      "0.873580600323 210 230\n",
      "0.873580600323 220 230\n",
      "0.873580600323 230 230\n",
      "0.873580600323 240 230\n",
      "0.872238751251 250 230\n",
      "0.873435819036 260 230\n",
      "0.878096696236 270 230\n",
      "0.878096696236 280 230\n",
      "0.879001737419 290 230\n",
      "0.859421034826 50 240\n",
      "0.857864583162 60 240\n",
      "0.861930677376 70 240\n",
      "0.861959125871 80 240\n",
      "0.863396943357 90 240\n",
      "0.862985628806 100 240\n",
      "0.864538260791 110 240\n",
      "0.867313821729 120 240\n",
      "0.86354074249 130 240\n",
      "0.866602292953 140 240\n",
      "0.867998933846 150 240\n",
      "0.865985661242 160 240\n",
      "0.868503858306 170 240\n",
      "0.869963699522 180 240\n",
      "0.871399969949 190 240\n",
      "0.871399969949 200 240\n",
      "0.870931122691 210 240\n",
      "0.870931122691 220 240\n",
      "0.870931122691 230 240\n",
      "0.872254146663 240 240\n",
      "0.872254146663 250 240\n",
      "0.874909127268 260 240\n",
      "0.874909127268 270 240\n",
      "0.874909127268 280 240\n",
      "0.876240198463 290 240\n",
      "0.854671652345 50 250\n",
      "0.859174520568 60 250\n",
      "0.864951655999 70 250\n",
      "0.866185968949 80 250\n",
      "0.864322020471 90 250\n",
      "0.865285525577 100 250\n",
      "0.869622020234 110 250\n",
      "0.865770450342 120 250\n",
      "0.868421819685 130 250\n",
      "0.867000330592 140 250\n",
      "0.867000330592 150 250\n",
      "0.868421819685 160 250\n",
      "0.868095181283 170 250\n",
      "0.866261255539 180 250\n",
      "0.866387595933 190 250\n",
      "0.866387595933 200 250\n",
      "0.867668166402 210 250\n",
      "0.867668166402 220 250\n",
      "0.867668166402 230 250\n",
      "0.866014417821 240 250\n",
      "0.867193714731 250 250\n",
      "0.86854081756 260 250\n",
      "0.870351631018 270 250\n",
      "0.870351631018 280 250\n",
      "0.871504497089 290 250\n",
      "0.854095493777 50 260\n",
      "0.857200497846 60 260\n",
      "0.857756973328 70 260\n",
      "0.857691232143 80 260\n",
      "0.856026790787 90 260\n",
      "0.864639844075 100 260\n",
      "0.863236711173 110 260\n",
      "0.865305508308 120 260\n",
      "0.86788932376 130 260\n",
      "0.86788932376 140 260\n",
      "0.86788932376 150 260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.865887395041 160 260\n",
      "0.865887395041 170 260\n",
      "0.862775439313 180 260\n",
      "0.861476573761 190 260\n",
      "0.862915463729 200 260\n",
      "0.864339370162 210 260\n",
      "0.867063841791 220 260\n",
      "0.865872164983 230 260\n",
      "0.86725438371 240 260\n",
      "0.86725438371 250 260\n",
      "0.86725438371 260 260\n",
      "0.865487228389 270 260\n",
      "0.865234871287 280 260\n",
      "0.865234871287 290 260\n",
      "0.855895665795 50 270\n",
      "0.851513925193 60 270\n",
      "0.853307364128 70 270\n",
      "0.855893645269 80 270\n",
      "0.858857803629 90 270\n",
      "0.859503086069 100 270\n",
      "0.863094285756 110 270\n",
      "0.864125886479 120 270\n",
      "0.864125886479 130 270\n",
      "0.862070340035 140 270\n",
      "0.860253948262 150 270\n",
      "0.858820156741 160 270\n",
      "0.860286077582 170 270\n",
      "0.860286077582 180 270\n",
      "0.864723525999 190 270\n",
      "0.866138629931 200 270\n",
      "0.864497397792 210 270\n",
      "0.864497397792 220 270\n",
      "0.864497397792 230 270\n",
      "0.862738849596 240 270\n",
      "0.864228166131 250 270\n",
      "0.865534453287 260 270\n",
      "0.865558324504 270 270\n",
      "0.868231762652 280 270\n",
      "0.868231762652 290 270\n",
      "0.851810447292 50 280\n",
      "0.855878116206 60 280\n",
      "0.853934498454 70 280\n",
      "0.855586848222 80 280\n",
      "0.85962701785 90 280\n",
      "0.862284518492 100 280\n",
      "0.860554820126 110 280\n",
      "0.859123714559 120 280\n",
      "0.859123714559 130 280\n",
      "0.860539078324 140 280\n",
      "0.861498094597 150 280\n",
      "0.859526630257 160 280\n",
      "0.857485498331 170 280\n",
      "0.860457018933 180 280\n",
      "0.858832046229 190 280\n",
      "0.858544316402 200 280\n",
      "0.85997289284 210 280\n",
      "0.85997289284 220 280\n",
      "0.86269771199 230 280\n",
      "0.86269771199 240 280\n",
      "0.86269771199 250 280\n",
      "0.86388920295 260 280\n",
      "0.865840336649 270 280\n",
      "0.868493670223 280 280\n",
      "0.869674819317 290 280\n",
      "0.868264892418 50 290\n",
      "0.86394855828 60 290\n",
      "0.862525615605 70 290\n",
      "0.860721290365 80 290\n",
      "0.864918472968 90 290\n",
      "0.866620701584 100 290\n",
      "0.865987970213 110 290\n",
      "0.870016405825 120 290\n",
      "0.871159237121 130 290\n",
      "0.874203326284 140 290\n",
      "0.875518654466 150 290\n",
      "0.875011079721 160 290\n",
      "0.872330634361 170 290\n",
      "0.872330634361 180 290\n",
      "0.874780189677 190 290\n",
      "0.874315831585 200 290\n",
      "0.875758415635 210 290\n",
      "0.87580247518 220 290\n",
      "0.877122366179 230 290\n",
      "0.878318575571 240 290\n",
      "0.878318575571 250 290\n",
      "0.879509336247 260 290\n",
      "0.878904422133 270 290\n",
      "0.878904422133 280 290\n",
      "0.881509455145 290 290\n",
      "0.866942408333 50 300\n",
      "0.863050539109 60 300\n",
      "0.864458289805 70 300\n",
      "0.859487829672 80 300\n",
      "0.858972730455 90 300\n",
      "0.863058879585 100 300\n",
      "0.867420452974 110 300\n",
      "0.865980301919 120 300\n",
      "0.865805903695 130 300\n",
      "0.868287724597 140 300\n",
      "0.869531324091 150 300\n",
      "0.868075359605 160 300\n",
      "0.870803460286 170 300\n",
      "0.872152147713 180 300\n",
      "0.870450492918 190 300\n",
      "0.870450492918 200 300\n",
      "0.870450492918 210 300\n",
      "0.871739192355 220 300\n",
      "0.870267563581 230 300\n",
      "0.870267563581 240 300\n",
      "0.869788743148 250 300\n",
      "0.872431355424 260 300\n",
      "0.872755334831 270 300\n",
      "0.872755334831 280 300\n",
      "0.872755334831 290 300\n",
      "0.869060230295 50 310\n",
      "0.864563431662 60 310\n",
      "0.865901206725 70 310\n",
      "0.866607497482 80 310\n",
      "0.872861142007 90 310\n",
      "0.875415810797 100 310\n",
      "0.873894982439 110 310\n",
      "0.876586603884 120 310\n",
      "0.87585736596 130 310\n",
      "0.874083104214 140 310\n",
      "0.873647906661 150 310\n",
      "0.871710928435 160 310\n",
      "0.871710928435 170 310\n",
      "0.871321741697 180 310\n",
      "0.871321741697 190 310\n",
      "0.873948744044 200 310\n",
      "0.873948744044 210 310\n",
      "0.876476090583 220 310\n",
      "0.874581883559 230 310\n",
      "0.875882501135 240 310\n",
      "0.874633219591 250 310\n",
      "0.87494192395 260 310\n",
      "0.87494192395 270 310\n",
      "0.873745948522 280 310\n",
      "0.873745948522 290 310\n",
      "0.863851501577 50 320\n",
      "0.868642666401 60 320\n",
      "0.868471909777 70 320\n",
      "0.867565403441 80 320\n",
      "0.869833093653 90 320\n",
      "0.874410908664 100 320\n",
      "0.874236883934 110 320\n",
      "0.875506870595 120 320\n",
      "0.877032981816 130 320\n",
      "0.880986313243 140 320\n",
      "0.880904484932 150 320\n",
      "0.882228893639 160 320\n",
      "0.883532189002 170 320\n",
      "0.881604331377 180 320\n",
      "0.875195753375 190 320\n",
      "0.876422041583 200 320\n",
      "0.876422041583 210 320\n",
      "0.873164496579 220 320\n",
      "0.871813946404 230 320\n",
      "0.871813946404 240 320\n",
      "0.871813946404 250 320\n",
      "0.871813946404 260 320\n",
      "0.873182646516 270 320\n",
      "0.869865536403 280 320\n",
      "0.871076673361 290 320\n",
      "0.863555968789 50 330\n",
      "0.864716574628 60 330\n",
      "0.867033432748 70 330\n",
      "0.871332719784 80 330\n",
      "0.872058436376 90 330\n",
      "0.87036108249 100 330\n",
      "0.874079629774 110 330\n",
      "0.875524283261 120 330\n",
      "0.880862899968 130 330\n",
      "0.881704349818 140 330\n",
      "0.881704349818 150 330\n",
      "0.880258776738 160 330\n",
      "0.880258776738 170 330\n",
      "0.881728555012 180 330\n",
      "0.881852116003 190 330\n",
      "0.8804052362 200 330\n",
      "0.878708179494 210 330\n",
      "0.878708179494 220 330\n",
      "0.879935474957 230 330\n",
      "0.878060813418 240 330\n",
      "0.877468950728 250 330\n",
      "0.877468950728 260 330\n",
      "0.877485170998 270 330\n",
      "0.878690920505 280 330\n",
      "0.877937388198 290 330\n",
      "0.852995466532 50 340\n",
      "0.860686448565 60 340\n",
      "0.865284045449 70 340\n",
      "0.864529290016 80 340\n",
      "0.868700233451 90 340\n",
      "0.874091312323 100 340\n",
      "0.871314193118 110 340\n",
      "0.871308765093 120 340\n",
      "0.872649360416 130 340\n",
      "0.87797519332 140 340\n",
      "0.877926417857 150 340\n",
      "0.877926417857 160 340\n",
      "0.872662277284 170 340\n",
      "0.87405179825 180 340\n",
      "0.872323605662 190 340\n",
      "0.872323605662 200 340\n",
      "0.871925134458 210 340\n",
      "0.871925134458 220 340\n",
      "0.869982781124 230 340\n",
      "0.869828401635 240 340\n",
      "0.869828401635 250 340\n",
      "0.869920037319 260 340\n",
      "0.868603703736 270 340\n",
      "0.869391603082 280 340\n",
      "0.870528504824 290 340\n",
      "0.85711201523 50 350\n",
      "0.861654032333 60 350\n",
      "0.862890803689 70 350\n",
      "0.866481473671 80 350\n",
      "0.863272850405 90 350\n",
      "0.864291986413 100 350\n",
      "0.86715457462 110 350\n",
      "0.866858111975 120 350\n",
      "0.863750911173 130 350\n",
      "0.863750911173 140 350\n",
      "0.86664076869 150 350\n",
      "0.868030010512 160 350\n",
      "0.866259137063 170 350\n",
      "0.866146013938 180 350\n",
      "0.862777583079 190 350\n",
      "0.86302646302 200 350\n",
      "0.864254513208 210 350\n",
      "0.864254513208 220 350\n",
      "0.866880496171 230 350\n",
      "0.866880496171 240 350\n",
      "0.866092631229 250 350\n",
      "0.867365703321 260 350\n",
      "0.867365703321 270 350\n",
      "0.868628784298 280 350\n",
      "0.86988234176 290 350\n",
      "0.858766751273 50 360\n",
      "0.860405097989 60 360\n",
      "0.861006536925 70 360\n",
      "0.861908239338 80 360\n",
      "0.860545860756 90 360\n",
      "0.864790223187 100 360\n",
      "0.865460098725 110 360\n",
      "0.866527090976 120 360\n",
      "0.867964182342 130 360\n",
      "0.866047148112 140 360\n",
      "0.866047148112 150 360\n",
      "0.865899891589 160 360\n",
      "0.863198858745 170 360\n",
      "0.861267970245 180 360\n",
      "0.861221773697 190 360\n",
      "0.862533927439 200 360\n",
      "0.864091537808 210 360\n",
      "0.862015661278 220 360\n",
      "0.85875200087 230 360\n",
      "0.85875200087 240 360\n",
      "0.860111188905 250 360\n",
      "0.861388601322 260 360\n",
      "0.861327810817 270 360\n",
      "0.861371156715 280 360\n",
      "0.862639148297 290 360\n",
      "0.846919004383 50 370\n",
      "0.851676055806 60 370\n",
      "0.854442243902 70 370\n",
      "0.853992539353 80 370\n",
      "0.852277835558 90 370\n",
      "0.852340518979 100 370\n",
      "0.854768769782 110 370\n",
      "0.856160279535 120 370\n",
      "0.856160279535 130 370\n",
      "0.853482914795 140 370\n",
      "0.854861454845 150 370\n",
      "0.853313610771 160 370\n",
      "0.853145464011 170 370\n",
      "0.853145464011 180 370\n",
      "0.854636308961 190 370\n",
      "0.857764215993 200 370\n",
      "0.859454099055 210 370\n",
      "0.86076266224 220 370\n",
      "0.862593922833 230 370\n",
      "0.862593922833 240 370\n",
      "0.865344241159 250 370\n",
      "0.865344241159 260 370\n",
      "0.865344241159 270 370\n",
      "0.866587460904 280 370\n",
      "0.866587460904 290 370\n",
      "0.848330705345 50 380\n",
      "0.84963685583 60 380\n",
      "0.848146544305 70 380\n",
      "0.849381175475 80 380\n",
      "0.851339900309 90 380\n",
      "0.852453867027 100 380\n",
      "0.850919621685 110 380\n",
      "0.850681391543 120 380\n",
      "0.850940116678 130 380\n",
      "0.850940116678 140 380\n",
      "0.852591616553 150 380\n",
      "0.850922966523 160 380\n",
      "0.852313145681 170 380\n",
      "0.852249139549 180 380\n",
      "0.852249139549 190 380\n",
      "0.852307856089 200 380\n",
      "0.856361383258 210 380\n",
      "0.85791065397 220 380\n",
      "0.855788258877 230 380\n",
      "0.858913809862 240 380\n",
      "0.856860902526 250 380\n",
      "0.858180356578 260 380\n",
      "0.854973254664 270 380\n",
      "0.856282205614 280 380\n",
      "0.856282205614 290 380\n",
      "0.842869072361 50 390\n",
      "0.848945181821 60 390\n",
      "0.854290656848 70 390\n",
      "0.856922181402 80 390\n",
      "0.857007122657 90 390\n",
      "0.853886417534 100 390\n",
      "0.853886417534 110 390\n",
      "0.853652063202 120 390\n",
      "0.852196817687 130 390\n",
      "0.850423915042 140 390\n",
      "0.850423915042 150 390\n",
      "0.850423915042 160 390\n",
      "0.853313031374 170 390\n",
      "0.853313031374 180 390\n",
      "0.851768689715 190 390\n",
      "0.851505622652 200 390\n",
      "0.852845061356 210 390\n",
      "0.855873463174 220 390\n",
      "0.855468777689 230 390\n",
      "0.853891199048 240 390\n",
      "0.853891199048 250 390\n",
      "0.855407982651 260 390\n",
      "0.85671246172 270 390\n",
      "0.856684582637 280 390\n",
      "0.856470766909 290 390\n"
     ]
    }
   ],
   "source": [
    "bestscores = []\n",
    "for features in range(120, 400, 10):\n",
    "    for cval in range(50, 300, 10):\n",
    "        f05, precision, recall, predictions = onepass(cval/ 10000, features, termdoc, classvec)\n",
    "        print(f05, cval, features)\n",
    "        bestscores.append((f05, cval, features))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.88353218900242325, 170, 320)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestscores.sort()\n",
    "bestscores[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the best model more specifically. Note that precision is good, which is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.883532189002 0.949222876241 0.776111111111 322\n"
     ]
    }
   ],
   "source": [
    "f05, precision, recall, predictions = onepass(.0170, 320, termdoc, classvec)\n",
    "print(f05, precision, recall, sum(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Produce a model to export\n",
    "\n",
    "Ultimately we have to make a model to use, and this can't be crossvalidated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained.\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(termdoc.iloc[ : , 0 : 330])\n",
    "model = LogisticRegression(C = .0260)\n",
    "model.fit(data, classvec)\n",
    "print('Model trained.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('fictionreview_scaler.pkl', mode = 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "with open('fictionreview_model.pkl', mode = 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "words = list(termdoc.columns)\n",
    "with open('fictionreview_vocab.txt', mode = 'w', encoding = 'utf-8') as f:\n",
    "    for w in words[0: 400]:\n",
    "        f.write(w + '\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(termdoc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voyages -0.267336648243\n",
      "letters -0.219930648761\n",
      "subject -0.184078101237\n",
      "year -0.141330701794\n",
      "came -0.136963180258\n",
      "set -0.134250743054\n",
      "#rareword -0.128230321524\n",
      "every -0.123960378007\n",
      "history -0.120813234593\n",
      "sense -0.118523043698\n",
      "years -0.111317361256\n",
      "have -0.111218886601\n",
      "under -0.105723492365\n",
      "here -0.104435215001\n",
      "state -0.096682472146\n",
      "no -0.0928452440297\n",
      "#romannumeral -0.0924782114431\n",
      "i -0.0922178266268\n",
      "think -0.0893390356446\n",
      "something -0.0890621066751\n",
      "during -0.085242941688\n",
      "knowledge -0.0821307371905\n",
      "h -0.0819647243647\n",
      "must -0.0811553627844\n",
      "among -0.0762262592473\n",
      "own -0.0753208020356\n",
      "even -0.074267723266\n",
      "those -0.0735561095232\n",
      "age -0.0727081230924\n",
      "volume -0.072214208641\n",
      "makes -0.0716348365576\n",
      "cannot -0.0706946825306\n",
      "each -0.0696362384984\n",
      "so -0.0695204954841\n",
      "me -0.0684433284252\n",
      "co -0.0661531470648\n",
      "my -0.0638831792641\n",
      "till -0.063664709479\n",
      "matter -0.0631487038202\n",
      "also -0.0630160086945\n",
      "p -0.0624107517832\n",
      "this -0.0593533480628\n",
      "j -0.0579417904779\n",
      "ill -0.0574710404869\n",
      "natural -0.0571052468132\n",
      "fact -0.0557697167792\n",
      "account -0.0555350442469\n",
      "head -0.0549893375056\n",
      "light -0.0545793811186\n",
      "most -0.0532787382589\n",
      "now -0.0517841193371\n",
      "second -0.0517308545051\n",
      "while -0.0509419345182\n",
      "seems -0.0503292803535\n",
      "between -0.0501565383511\n",
      "others -0.0494165352734\n",
      "general -0.0493751539382\n",
      "doubt -0.0491866842085\n",
      "us -0.0482902984569\n",
      "t -0.048273282619\n",
      "w -0.0481849780198\n",
      "enough -0.0470139741153\n",
      "country -0.0452795773654\n",
      "art -0.0448563179267\n",
      "whose -0.042558695719\n",
      "there -0.0424100536312\n",
      "come -0.0419864485728\n",
      "character -0.0419235653578\n",
      "st -0.0405970756509\n",
      "mind -0.0402016162545\n",
      "things -0.0384503143844\n",
      "place -0.0377349715885\n",
      "such -0.0377151720366\n",
      "spirit -0.0370707429239\n",
      "many -0.0366719523053\n",
      "taken -0.0365311431602\n",
      "point -0.0350028802023\n",
      "when -0.0346913472455\n",
      "present -0.0338389026589\n",
      "being -0.0335434364083\n",
      "high -0.0331857857334\n",
      "name -0.0326087554275\n",
      "#placename -0.0318768568724\n",
      "said -0.031312773458\n",
      "nature -0.0311722273997\n",
      "take -0.0310497637783\n",
      "g -0.0307971346041\n",
      "about -0.0302240232892\n",
      "thought -0.0290784296006\n",
      "few -0.0290098629215\n",
      "can -0.0286144356246\n",
      "given -0.0254930362006\n",
      "their -0.0253633675466\n",
      "nor -0.0246057805235\n",
      "kind -0.0245327063843\n",
      "english -0.0245181203738\n",
      "interesting -0.0238757839676\n",
      "o -0.0235951584125\n",
      "least -0.0232183331893\n",
      "might -0.021479994526\n",
      "because -0.0213989443428\n",
      "against -0.0209732089246\n",
      "making -0.0203359004855\n",
      "know -0.0195745564342\n",
      "great -0.0188830853365\n",
      "f -0.0186477492756\n",
      "these -0.0184933074209\n",
      "it -0.0179135639277\n",
      "mr -0.016971869665\n",
      "writing -0.016788193318\n",
      "words -0.0155366622022\n",
      "give -0.0146969310265\n",
      "after -0.0139306596253\n",
      "put -0.0137855055933\n",
      "written -0.0133129141453\n",
      "house -0.0129862019652\n",
      "has -0.0128890648523\n",
      "left -0.012678927923\n",
      "d -0.0125840678989\n",
      "if -0.0124418459585\n",
      "without -0.0118730319512\n",
      "should -0.0117090949676\n",
      "was -0.0104020796665\n",
      "to -0.010318279284\n",
      "book -0.00928227707105\n",
      "will -0.00874711024336\n",
      "often -0.00867403986211\n",
      "means -0.00727887570727\n",
      "then -0.00582590496697\n",
      "day -0.00535656752433\n",
      "#personalname -0.00426280625977\n",
      "the -0.00293067717008\n",
      "almost -0.00277245094466\n",
      "which -0.00269887136724\n",
      "full -0.00224050926656\n",
      "time -0.00185312040468\n",
      "told -0.00158868292507\n",
      "world -0.00115704341737\n",
      "been -0.000462110077356\n",
      "and 0.00034581343427\n",
      "works 0.000577826622889\n",
      "but 0.000733990351022\n",
      "were 0.00115742826512\n",
      "that 0.00136501810149\n",
      "friend 0.00146621182153\n",
      "by 0.00188881815404\n",
      "s 0.00291185917942\n",
      "times 0.0030849175817\n",
      "itself 0.00369339715155\n",
      "a 0.00465794808906\n",
      "we 0.0052531537266\n",
      "true 0.00608276697427\n",
      "would 0.00669870687861\n",
      "back 0.00700428205587\n",
      "who 0.00712351529436\n",
      "all 0.00716100403215\n",
      "as 0.00756438992154\n",
      "far 0.00781003994666\n",
      "make 0.0095362327177\n",
      "whom 0.00973487001128\n",
      "however 0.010014929509\n",
      "whole 0.0101862541729\n",
      "at 0.0105233741052\n",
      "never 0.0106910130777\n",
      "them 0.0110865534595\n",
      "known 0.01146995842\n",
      "heart 0.0116257392824\n",
      "still 0.0124217446297\n",
      "m 0.0125661049809\n",
      "of 0.0131238482302\n",
      "work 0.0149846198169\n",
      "with 0.0157221993437\n",
      "having 0.0169728188369\n",
      "always 0.0174564306345\n",
      "either 0.0177339127588\n",
      "again 0.0178247419733\n",
      "away 0.0179056125908\n",
      "first 0.0182516684384\n",
      "found 0.0183080467307\n",
      "indeed 0.0186882171746\n",
      "once 0.0187403198565\n",
      "did 0.019059393793\n",
      "nothing 0.0192946416633\n",
      "men 0.0196658051605\n",
      "be 0.0204023137574\n",
      "public 0.0207430921743\n",
      "look 0.0210805445519\n",
      "may 0.0221623183313\n",
      "had 0.0224733112697\n",
      "out 0.0225221442214\n",
      "really 0.0230196042137\n",
      "#notenglishword 0.0232245614003\n",
      "better 0.0233023133865\n",
      "go 0.0236021532996\n",
      "an 0.0244196110126\n",
      "b 0.0244772854399\n",
      "old 0.0250839491911\n",
      "new 0.0251194524968\n",
      "she 0.0251915362048\n",
      "form 0.027391094259\n",
      "author 0.0275317743788\n",
      "both 0.0299724076481\n",
      "is 0.0301904453002\n",
      "himself 0.0305885373644\n",
      "where 0.030656313587\n",
      "upon 0.0310229197132\n",
      "what 0.0312285331007\n",
      "could 0.0319022165342\n",
      "very 0.0321181067082\n",
      "feeling 0.0326068366279\n",
      "made 0.0327434882629\n",
      "seen 0.0327521734312\n",
      "its 0.0336248484348\n",
      "manner 0.0347057959296\n",
      "thing 0.0350436999319\n",
      "good 0.0350477723284\n",
      "end 0.0356508568565\n",
      "death 0.0359621535045\n",
      "half 0.0359796413732\n",
      "large 0.0360459897493\n",
      "same 0.037297991481\n",
      "within 0.0397905522085\n",
      "miss 0.0398840624725\n",
      "over 0.0398866907179\n",
      "than 0.041095869948\n",
      "little 0.0419198142574\n",
      "shall 0.0422357753334\n",
      "last 0.0422913577385\n",
      "power 0.0425133706721\n",
      "long 0.0434739281572\n",
      "side 0.0435410426947\n",
      "do 0.0443839268592\n",
      "her 0.0448768386113\n",
      "r 0.0449414654328\n",
      "another 0.0459242044875\n",
      "find 0.0464497319151\n",
      "three 0.0465230934823\n",
      "in 0.0471920970238\n",
      "perhaps 0.0477251864402\n",
      "people 0.047951373157\n",
      "style 0.0484499143478\n",
      "called 0.0485784739193\n",
      "well 0.0492417384009\n",
      "right 0.0512162409547\n",
      "some 0.0514723891032\n",
      "e 0.0520051084894\n",
      "part 0.052669225039\n",
      "happy 0.0532073477915\n",
      "done 0.0533433111421\n",
      "his 0.0544687408778\n",
      "are 0.0555156612819\n",
      "through 0.0563537313437\n",
      "from 0.0563939326073\n",
      "woman 0.0568025921002\n",
      "before 0.0579673606578\n",
      "human 0.0580605910042\n",
      "interest 0.058316076189\n",
      "or 0.058747597957\n",
      "course 0.0605108305913\n",
      "case 0.0609846334306\n",
      "books 0.0610797752661\n",
      "days 0.0615147736894\n",
      "n 0.0615338959634\n",
      "certain 0.0623849343254\n",
      "mrs 0.0627226532349\n",
      "rather 0.0638784698874\n",
      "yet 0.0655258890264\n",
      "see 0.0657874796584\n",
      "for 0.0663269701121\n",
      "other 0.0680066551101\n",
      "hand 0.0686514803644\n",
      "just 0.0695397008055\n",
      "into 0.0700735261552\n",
      "short 0.071371502395\n",
      "on 0.0714208774271\n",
      "reader 0.0720411402214\n",
      "though 0.0730058155936\n",
      "man 0.0731621135729\n",
      "more 0.0734635058028\n",
      "tales 0.0749414535025\n",
      "writer 0.0759134101646\n",
      "like 0.0777321171455\n",
      "they 0.0784412226999\n",
      "real 0.0803576790446\n",
      "strong 0.0804077124566\n",
      "quite 0.0831371129905\n",
      "up 0.08316937591\n",
      "thus 0.0839261616054\n",
      "any 0.0871584980696\n",
      "two 0.0880585575741\n",
      "not 0.0885725516461\n",
      "read 0.0895806553096\n",
      "themselves 0.0905744046294\n",
      "life 0.0923989521979\n",
      "him 0.0932611236196\n",
      "he 0.0944057340863\n",
      "poor 0.0946755253153\n",
      "way 0.0956617552717\n",
      "much 0.0961346394364\n",
      "young 0.0966515310391\n",
      "lie 0.0983232221604\n",
      "ever 0.100005675354\n",
      "one 0.106457045606\n",
      "eyes 0.10658397355\n",
      "only 0.109744926359\n",
      "say 0.112697073291\n",
      "son 0.114971127362\n",
      "love 0.11497617907\n",
      "down 0.11552668855\n",
      "wife 0.116582063442\n",
      "tale 0.116762035581\n",
      "does 0.117267783931\n",
      "father 0.118064041624\n",
      "vols 0.11855795717\n",
      "best 0.119173044195\n",
      "off 0.123229560539\n",
      "less 0.12467696688\n",
      "lady 0.124760498789\n",
      "how 0.128435398881\n",
      "our 0.129336625701\n",
      "let 0.131118011479\n",
      "characters 0.137975400738\n",
      "readers 0.144270217572\n",
      "too 0.15197951156\n",
      "hero 0.173121397962\n",
      "#matchquality 0.204093353899\n",
      "story 0.207297950709\n",
      "you 0.217236794988\n",
      "novels 0.265055049429\n",
      "novel 0.277278388809\n"
     ]
    }
   ],
   "source": [
    "features = list(zip(list(model.coef_[0]), words))\n",
    "features.sort()\n",
    "for x, y in features:\n",
    "    print(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.array(termdoc.iloc[1 , ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = vector[0:210].reshape(1, -1)\n",
    "vecscaled = scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25452809,  0.74547191]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(vecscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classvec[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
